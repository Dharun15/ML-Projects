{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTeS3W5Xhv7Z",
        "outputId": "1745f6cc-a27e-4104-a598-ed6a852b8b2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'bark'...\n",
            "remote: Enumerating objects: 835, done.\u001b[K\n",
            "remote: Counting objects: 100% (804/804), done.\u001b[K\n",
            "remote: Compressing objects: 100% (804/804), done.\u001b[K\n",
            "remote: Total 835 (delta 6), reused 0 (delta 0), pack-reused 31\u001b[K\n",
            "Receiving objects: 100% (835/835), 1.55 MiB | 5.58 MiB/s, done.\n",
            "Resolving deltas: 100% (18/18), done.\n",
            "Filtering content: 100% (790/790), 12.67 GiB | 34.64 MiB/s, done.\n",
            "Encountered 2 file(s) that may not have been copied correctly on Windows:\n",
            "\tpytorch_model.bin\n",
            "\ttext_2.pt\n",
            "\n",
            "See: `git lfs help smudge` for more details.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://huggingface.co/suno/bark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pIQ7oUCWhSXU",
        "outputId": "79d0db29-c3a1-411c-96c9-c65c9cdb6c1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting TTS\n",
            "  Downloading TTS-0.16.5-cp310-cp310-manylinux1_x86_64.whl (809 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.3/809.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cython==0.29.30 (from TTS)\n",
            "  Downloading Cython-0.29.30-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (1.10.1)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from TTS) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from TTS) (2.0.2+cu118)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (from TTS) (0.12.1)\n",
            "Collecting librosa==0.10.0.* (from TTS)\n",
            "  Downloading librosa-0.10.0.post2-py3-none-any.whl (253 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting inflect==5.6.0 (from TTS)\n",
            "  Downloading inflect-5.6.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from TTS) (4.66.1)\n",
            "Collecting anyascii (from TTS)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from TTS) (6.0.1)\n",
            "Requirement already satisfied: fsspec>=2021.04.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from TTS) (3.8.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from TTS) (23.1)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from TTS) (2.2.5)\n",
            "Collecting pysbd (from TTS)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting umap-learn==0.5.1 (from TTS)\n",
            "  Downloading umap-learn-0.5.1.tar.gz (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from TTS) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from TTS) (3.7.1)\n",
            "Collecting trainer (from TTS)\n",
            "  Downloading trainer-0.0.31-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coqpit>=0.0.16 (from TTS)\n",
            "  Downloading coqpit-0.0.17-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from TTS) (0.42.1)\n",
            "Collecting pypinyin (from TTS)\n",
            "  Downloading pypinyin-0.49.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gruut[de,es,fr]==2.2.3 (from TTS)\n",
            "  Downloading gruut-2.2.3.tar.gz (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jamo (from TTS)\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from TTS) (3.8.1)\n",
            "Collecting g2pkk>=0.1.1 (from TTS)\n",
            "  Downloading g2pkk-0.1.2-py3-none-any.whl (25 kB)\n",
            "Collecting bangla==0.0.2 (from TTS)\n",
            "  Downloading bangla-0.0.2-py2.py3-none-any.whl (6.2 kB)\n",
            "Collecting bnnumerizer (from TTS)\n",
            "  Downloading bnnumerizer-0.0.2.tar.gz (4.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bnunicodenormalizer==0.1.1 (from TTS)\n",
            "  Downloading bnunicodenormalizer-0.1.1.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting k-diffusion (from TTS)\n",
            "  Downloading k_diffusion-0.0.16-py3-none-any.whl (25 kB)\n",
            "Collecting einops (from TTS)\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers (from TTS)\n",
            "  Downloading transformers-4.32.1-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting encodec (from TTS)\n",
            "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy==1.22.0 (from TTS)\n",
            "  Downloading numpy-1.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numba==0.57.0 (from TTS)\n",
            "  Downloading numba-0.57.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Babel<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.12.1)\n",
            "Collecting dateparser~=1.1.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading dateparser-1.1.8-py2.py3-none-any.whl (293 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gruut-ipa<1.0,>=0.12.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut-ipa-0.13.0.tar.gz (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_en~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut_lang_en-2.0.0.tar.gz (15.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jsonlines~=1.2.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading jsonlines-1.2.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting networkx<3.0.0,>=2.5.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting num2words<1.0.0,>=0.5.10 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading num2words-0.5.12-py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-crfsuite~=0.9.7 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading python_crfsuite-0.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.5/993.5 kB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gruut_lang_fr~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut_lang_fr-2.0.2.tar.gz (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_es~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut_lang_es-2.0.0.tar.gz (31.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_de~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut_lang_de-2.0.0.tar.gz (18.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (3.0.0)\n",
            "INFO: pip is looking at multiple versions of librosa to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting librosa==0.10.0.* (from TTS)\n",
            "  Downloading librosa-0.10.0.post1-py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading librosa-0.10.0-py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.9/252.9 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (1.7.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (0.3.6)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (4.7.1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (1.0.5)\n",
            "Collecting llvmlite<0.41,>=0.40.0dev0 (from numba==0.57.0->TTS)\n",
            "  Downloading llvmlite-0.40.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pynndescent>=0.5 (from umap-learn==0.5.1->TTS)\n",
            "  Downloading pynndescent-0.5.10.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile->TTS) (1.15.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->TTS) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->TTS) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->TTS) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->TTS) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->TTS) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->TTS) (16.0.6)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->TTS) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->TTS) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->TTS) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->TTS) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->TTS) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->TTS) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->TTS) (1.3.1)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask->TTS) (2.3.7)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->TTS) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask->TTS) (8.1.7)\n",
            "Collecting accelerate (from k-diffusion->TTS)\n",
            "  Downloading accelerate-0.22.0-py3-none-any.whl (251 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.2/251.2 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting clean-fid (from k-diffusion->TTS)\n",
            "  Downloading clean_fid-0.1.35-py3-none-any.whl (26 kB)\n",
            "Collecting clip-anytorch (from k-diffusion->TTS)\n",
            "  Downloading clip_anytorch-2.5.2-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonmerge (from k-diffusion->TTS)\n",
            "  Downloading jsonmerge-1.9.2-py3-none-any.whl (19 kB)\n",
            "Collecting kornia (from k-diffusion->TTS)\n",
            "  Downloading kornia-0.7.0-py2.py3-none-any.whl (705 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m705.7/705.7 kB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (9.4.0)\n",
            "Collecting resize-right (from k-diffusion->TTS)\n",
            "  Downloading resize_right-0.0.2-py3-none-any.whl (8.9 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (0.19.3)\n",
            "Collecting torchdiffeq (from k-diffusion->TTS)\n",
            "  Downloading torchdiffeq-0.2.3-py3-none-any.whl (31 kB)\n",
            "Collecting torchsde (from k-diffusion->TTS)\n",
            "  Downloading torchsde-0.2.5-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (0.15.2+cu118)\n",
            "Collecting wandb (from k-diffusion->TTS)\n",
            "  Downloading wandb-0.15.9-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS) (2.8.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->TTS) (2023.6.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->TTS) (2023.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from trainer->TTS) (5.9.5)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from trainer->TTS) (2.12.3)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers->TTS)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->TTS) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers->TTS)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m117.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers->TTS)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile->TTS) (2.21)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser~=1.1.0->gruut[de,es,fr]==2.2.3->TTS) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->TTS) (2.1.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from jsonlines~=1.2.0->gruut[de,es,fr]==2.2.3->TTS) (1.16.0)\n",
            "Collecting docopt>=0.6.2 (from num2words<1.0.0,>=0.5.10->gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa==0.10.0.*->TTS) (3.10.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->TTS) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->TTS) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->TTS) (2023.7.22)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa==0.10.0.*->TTS) (3.2.0)\n",
            "Collecting ftfy (from clip-anytorch->k-diffusion->TTS)\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema>2.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonmerge->k-diffusion->TTS) (4.19.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->k-diffusion->TTS) (2.31.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->k-diffusion->TTS) (2023.8.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->k-diffusion->TTS) (1.4.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->TTS) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (1.57.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (3.4.4)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (0.7.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (0.41.2)\n",
            "Collecting boltons>=20.2.1 (from torchsde->k-diffusion->TTS)\n",
            "  Downloading boltons-23.0.0-py2.py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trampoline>=0.1.2 (from torchsde->k-diffusion->TTS)\n",
            "  Downloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->k-diffusion->TTS)\n",
            "  Downloading GitPython-3.1.34-py3-none-any.whl (188 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.6/188.6 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0 (from wandb->k-diffusion->TTS)\n",
            "  Downloading sentry_sdk-1.30.0-py2.py3-none-any.whl (218 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.8/218.8 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->k-diffusion->TTS)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting pathtools (from wandb->k-diffusion->TTS)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb->k-diffusion->TTS)\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->TTS) (1.4.4)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->k-diffusion->TTS)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer->TTS) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer->TTS) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer->TTS) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->trainer->TTS) (1.3.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->TTS) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->TTS) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->TTS) (0.9.2)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->clip-anytorch->k-diffusion->TTS) (0.2.6)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->k-diffusion->TTS)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->trainer->TTS) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->trainer->TTS) (3.2.2)\n",
            "Building wheels for collected packages: bnunicodenormalizer, umap-learn, bnnumerizer, encodec, gruut-ipa, gruut_lang_de, gruut_lang_en, gruut_lang_es, gruut_lang_fr, pynndescent, gruut, docopt, pathtools\n",
            "  Building wheel for bnunicodenormalizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bnunicodenormalizer: filename=bnunicodenormalizer-0.1.1-py3-none-any.whl size=21895 sha256=f0250f6c1ae1bc29f4c1bbc06361e9a9c49bcac8db84f344cb99d37a5d1f383e\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/f6/01/9e68ecec7c7ea85fc9431cfac42eba1c5a5f6debe5070de5c7\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.1-py3-none-any.whl size=76543 sha256=587ce9c906c7735cf5bc238f2b5fc0c4765174692b00585c6ff7022ac710fc94\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/21/8e/802cb9c4c606a67139f538cb17bf3bf1b98b739a7900469953\n",
            "  Building wheel for bnnumerizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bnnumerizer: filename=bnnumerizer-0.0.2-py3-none-any.whl size=5259 sha256=4740a2af771d63225ae0f139840be2a9edae878f4eafcac1ca795f137f3dee52\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/6b/e8/223172e7d5c9f72df3ea1a0d9258f3a8ab5b28e827728edef5\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45760 sha256=e442afbab36c4b5b8eadcf2b7a1dc7b05a48cf597cf40f007387b4f22310373e\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/36/cb/81af8b985a5f5e0815312d5e52b41263237af07b977e6bcbf3\n",
            "  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-ipa: filename=gruut_ipa-0.13.0-py3-none-any.whl size=104871 sha256=390a25edb1f6ed6dd42db9d8cd8140eb505bed3098631a4ef30f7df1270590a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/18/49/e4f500ecdf0babe757953f844e4d7cd1ea81c5503c09bfe984\n",
            "  Building wheel for gruut_lang_de (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_de: filename=gruut_lang_de-2.0.0-py3-none-any.whl size=18498181 sha256=a9d7f0a6abd1357b92058f45d13a19338c512245e67c26caf196b0fefef7d1cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/9a/05/cfce98f0c41a1a540f15708c4a02df190b82d84cf91ef6bc7f\n",
            "  Building wheel for gruut_lang_en (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_en: filename=gruut_lang_en-2.0.0-py3-none-any.whl size=15297179 sha256=c4aaff0942d9aed928dda9e9a521a5496ef9c33d37ca3753cfa3ae570ddd9237\n",
            "  Stored in directory: /root/.cache/pip/wheels/10/9c/fb/77c655a9fbd78cdb9935d0ab65d80ddd0a3bcf7dbe18261650\n",
            "  Building wheel for gruut_lang_es (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_es: filename=gruut_lang_es-2.0.0-py3-none-any.whl size=32173797 sha256=c45bcb0664362b9a1beaf03820257fc8f6654958c0066b75f7cb05365b68bddf\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/0a/90/788d92c07744b329b9283e37b29b064f5db6b1bb0442a1a19b\n",
            "  Building wheel for gruut_lang_fr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_fr: filename=gruut_lang_fr-2.0.2-py3-none-any.whl size=10968767 sha256=13b79c8bf0a2c448cfd977f3659b29f114ca08193943677aa2061463b15ff238\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/21/be/d0436e3f1cf9bf38b9bb9b4a476399c77a1ab19f7172b45e19\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.10-py3-none-any.whl size=55615 sha256=3f30e244d73414f045e16f9c3953cafd2b6b04f7c7fd62c1441b7fe89e180c6d\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/38/5d/f60a40a66a9512b7e5e83517ebc2d1b42d857be97d135f1096\n",
            "  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut: filename=gruut-2.2.3-py3-none-any.whl size=75793 sha256=f290441abbf95674103d846b1fdc2ba59c4c65070c5be5b0df82be8f83d31dd8\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/57/a8/f9de532daf5214f53644f20f3a9e6f69269453c87df9c0a817\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=dc2ff28de6a488118d72f7abe6f3be61bdb7b24c77b23aa969172b5aad3aea02\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=0b2e2164cddd05ebb9057acf3d0daa2211711f67bda54f9c6beed75d7ce232d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built bnunicodenormalizer umap-learn bnnumerizer encodec gruut-ipa gruut_lang_de gruut_lang_en gruut_lang_es gruut_lang_fr pynndescent gruut docopt pathtools\n",
            "Installing collected packages: trampoline, tokenizers, safetensors, resize-right, python-crfsuite, pathtools, jamo, gruut_lang_fr, gruut_lang_es, gruut_lang_en, gruut_lang_de, docopt, boltons, bnunicodenormalizer, bnnumerizer, bangla, smmap, setproctitle, sentry-sdk, pysbd, pypinyin, numpy, num2words, networkx, llvmlite, jsonlines, inflect, gruut-ipa, ftfy, einops, docker-pycreds, cython, coqpit, anyascii, numba, huggingface-hub, gitdb, g2pkk, dateparser, transformers, gruut, GitPython, wandb, pynndescent, librosa, jsonmerge, umap-learn, torchsde, torchdiffeq, kornia, clip-anytorch, clean-fid, accelerate, trainer, k-diffusion, encodec, TTS\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.1\n",
            "    Uninstalling networkx-3.1:\n",
            "      Successfully uninstalled networkx-3.1\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.39.1\n",
            "    Uninstalling llvmlite-0.39.1:\n",
            "      Successfully uninstalled llvmlite-0.39.1\n",
            "  Attempting uninstall: inflect\n",
            "    Found existing installation: inflect 7.0.0\n",
            "    Uninstalling inflect-7.0.0:\n",
            "      Successfully uninstalled inflect-7.0.0\n",
            "  Attempting uninstall: cython\n",
            "    Found existing installation: Cython 0.29.36\n",
            "    Uninstalling Cython-0.29.36:\n",
            "      Successfully uninstalled Cython-0.29.36\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.56.4\n",
            "    Uninstalling numba-0.56.4:\n",
            "      Successfully uninstalled numba-0.56.4\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.10.1\n",
            "    Uninstalling librosa-0.10.1:\n",
            "      Successfully uninstalled librosa-0.10.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "plotnine 0.12.2 requires numpy>=1.23.0, but you have numpy 1.22.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GitPython-3.1.34 TTS-0.16.5 accelerate-0.22.0 anyascii-0.3.2 bangla-0.0.2 bnnumerizer-0.0.2 bnunicodenormalizer-0.1.1 boltons-23.0.0 clean-fid-0.1.35 clip-anytorch-2.5.2 coqpit-0.0.17 cython-0.29.30 dateparser-1.1.8 docker-pycreds-0.4.0 docopt-0.6.2 einops-0.6.1 encodec-0.1.1 ftfy-6.1.1 g2pkk-0.1.2 gitdb-4.0.10 gruut-2.2.3 gruut-ipa-0.13.0 gruut_lang_de-2.0.0 gruut_lang_en-2.0.0 gruut_lang_es-2.0.0 gruut_lang_fr-2.0.2 huggingface-hub-0.16.4 inflect-5.6.0 jamo-0.4.1 jsonlines-1.2.0 jsonmerge-1.9.2 k-diffusion-0.0.16 kornia-0.7.0 librosa-0.10.0 llvmlite-0.40.1 networkx-2.8.8 num2words-0.5.12 numba-0.57.0 numpy-1.22.0 pathtools-0.1.2 pynndescent-0.5.10 pypinyin-0.49.0 pysbd-0.3.4 python-crfsuite-0.9.9 resize-right-0.0.2 safetensors-0.3.3 sentry-sdk-1.30.0 setproctitle-1.3.2 smmap-5.0.0 tokenizers-0.13.3 torchdiffeq-0.2.3 torchsde-0.2.5 trainer-0.0.31 trampoline-0.1.2 transformers-4.32.1 umap-learn-0.5.1 wandb-0.15.9\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install TTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "a28337bd19a84811964d008c546c74a5",
            "1a6a1818fd3b4f4fa2650583dcdbe419",
            "542a4be4d80a45e6be7ff11b0fbde2bd"
          ]
        },
        "id": "nz56Ogjyh1Yx",
        "outputId": "02104733-5e33-4503-a324-669a36971529"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a28337bd19a84811964d008c546c74a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a6a1818fd3b4f4fa2650583dcdbe419",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "542a4be4d80a45e6be7ff11b0fbde2bd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from TTS.tts.configs.bark_config import BarkConfig\n",
        "from TTS.tts.models.bark import Bark\n",
        "from scipy.io.wavfile import write as write_wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qXe1WkFph6Td",
        "outputId": "89cd690c-38d3-4cc7-ce25-1883844efef8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://dl.fbaipublicfiles.com/encodec/v0/encodec_24khz-d7cc33bc.th\" to /root/.cache/torch/hub/checkpoints/encodec_24khz-d7cc33bc.th\n",
            "100%|██████████| 88.9M/88.9M [00:00<00:00, 164MB/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Bark(\n",
              "  (semantic_model): GPT(\n",
              "    (transformer): ModuleDict(\n",
              "      (wte): Embedding(129600, 1024)\n",
              "      (wpe): Embedding(1024, 1024)\n",
              "      (drop): Dropout(p=0.0, inplace=False)\n",
              "      (h): ModuleList(\n",
              "        (0-23): 24 x Block(\n",
              "          (ln_1): LayerNorm()\n",
              "          (attn): CausalSelfAttention(\n",
              "            (c_attn): Linear(in_features=1024, out_features=3072, bias=False)\n",
              "            (c_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ln_2): LayerNorm()\n",
              "          (mlp): MLP(\n",
              "            (c_fc): Linear(in_features=1024, out_features=4096, bias=False)\n",
              "            (c_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "            (gelu): GELU(approximate='none')\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln_f): LayerNorm()\n",
              "    )\n",
              "    (lm_head): Linear(in_features=1024, out_features=10048, bias=False)\n",
              "  )\n",
              "  (coarse_model): GPT(\n",
              "    (transformer): ModuleDict(\n",
              "      (wte): Embedding(12096, 1024)\n",
              "      (wpe): Embedding(1024, 1024)\n",
              "      (drop): Dropout(p=0.0, inplace=False)\n",
              "      (h): ModuleList(\n",
              "        (0-23): 24 x Block(\n",
              "          (ln_1): LayerNorm()\n",
              "          (attn): CausalSelfAttention(\n",
              "            (c_attn): Linear(in_features=1024, out_features=3072, bias=False)\n",
              "            (c_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ln_2): LayerNorm()\n",
              "          (mlp): MLP(\n",
              "            (c_fc): Linear(in_features=1024, out_features=4096, bias=False)\n",
              "            (c_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "            (gelu): GELU(approximate='none')\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln_f): LayerNorm()\n",
              "    )\n",
              "    (lm_head): Linear(in_features=1024, out_features=12096, bias=False)\n",
              "  )\n",
              "  (fine_model): FineGPT(\n",
              "    (transformer): ModuleDict(\n",
              "      (wtes): ModuleList(\n",
              "        (0-7): 8 x Embedding(1056, 1024)\n",
              "      )\n",
              "      (wpe): Embedding(1024, 1024)\n",
              "      (drop): Dropout(p=0.0, inplace=False)\n",
              "      (h): ModuleList(\n",
              "        (0-23): 24 x FineBlock(\n",
              "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): NonCausalSelfAttention(\n",
              "            (c_attn): Linear(in_features=1024, out_features=3072, bias=False)\n",
              "            (c_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): MLP(\n",
              "            (c_fc): Linear(in_features=1024, out_features=4096, bias=False)\n",
              "            (c_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "            (gelu): GELU(approximate='none')\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (lm_heads): ModuleList(\n",
              "      (0-6): 7 x Linear(in_features=1024, out_features=1056, bias=False)\n",
              "    )\n",
              "  )\n",
              "  (encodec): EncodecModel(\n",
              "    (encoder): SEANetEncoder(\n",
              "      (model): Sequential(\n",
              "        (0): SConv1d(\n",
              "          (conv): NormConv1d(\n",
              "            (conv): Conv1d(1, 32, kernel_size=(7,), stride=(1,))\n",
              "            (norm): Identity()\n",
              "          )\n",
              "        )\n",
              "        (1): SEANetResnetBlock(\n",
              "          (block): Sequential(\n",
              "            (0): ELU(alpha=1.0)\n",
              "            (1): SConv1d(\n",
              "              (conv): NormConv1d(\n",
              "                (conv): Conv1d(32, 16, kernel_size=(3,), stride=(1,))\n",
              "                (norm): Identity()\n",
              "              )\n",
              "            )\n",
              "            (2): ELU(alpha=1.0)\n",
              "            (3): SConv1d(\n",
              "              (conv): NormConv1d(\n",
              "                (conv): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
              "                (norm): Identity()\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (shortcut): SConv1d(\n",
              "            (conv): NormConv1d(\n",
              "              (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
              "              (norm): Identity()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (2): ELU(alpha=1.0)\n",
              "        (3): SConv1d(\n",
              "          (conv): NormConv1d(\n",
              "            (conv): Conv1d(32, 64, kernel_size=(4,), stride=(2,))\n",
              "            (norm): Identity()\n",
              "          )\n",
              "        )\n",
              "        (4): SEANetResnetBlock(\n",
              "          (block): Sequential(\n",
              "            (0): ELU(alpha=1.0)\n",
              "            (1): SConv1d(\n",
              "              (conv): NormConv1d(\n",
              "                (conv): Conv1d(64, 32, kernel_size=(3,), stride=(1,))\n",
              "                (norm): Identity()\n",
              "              )\n",
              "            )\n",
              "            (2): ELU(alpha=1.0)\n",
              "            (3): SConv1d(\n",
              "              (conv): NormConv1d(\n",
              "                (conv): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
              "                (norm): Identity()\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (shortcut): SConv1d(\n",
              "            (conv): NormConv1d(\n",
              "              (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
              "              (norm): Identity()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (5): ELU(alpha=1.0)\n",
              "        (6): SConv1d(\n",
              "          (conv): NormConv1d(\n",
              "            (conv): Conv1d(64, 128, kernel_size=(8,), stride=(4,))\n",
              "            (norm): Identity()\n",
              "          )\n",
              "        )\n",
              "        (7): SEANetResnetBlock(\n",
              "          (block): Sequential(\n",
              "            (0): ELU(alpha=1.0)\n",
              "            (1): SConv1d(\n",
              "              (conv): NormConv1d(\n",
              "                (conv): Conv1d(128, 64, kernel_size=(3,), stride=(1,))\n",
              "                (norm): Identity()\n",
              "              )\n",
              "            )\n",
              "            (2): ELU(alpha=1.0)\n",
              "            (3): SConv1d(\n",
              "              (conv): NormConv1d(\n",
              "                (conv): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
              "                (norm): Identity()\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (shortcut): SConv1d(\n",
              "            (conv): NormConv1d(\n",
              "              (conv): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
              "              (norm): Identity()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (8): ELU(alpha=1.0)\n",
              "        (9): SConv1d(\n",
              "          (conv): NormConv1d(\n",
              "            (conv): Conv1d(128, 256, kernel_size=(10,), stride=(5,))\n",
              "            (norm): Identity()\n",
              "          )\n",
              "        )\n",
              "        (10): SEANetResnetBlock(\n",
              "          (block): Sequential(\n",
              "            (0): ELU(alpha=1.0)\n",
              "            (1): SConv1d(\n",
              "              (conv): NormConv1d(\n",
              "                (conv): Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n",
              "                (norm): Identity()\n",
              "              )\n",
              "            )\n",
              "            (2): ELU(alpha=1.0)\n",
              "            (3): SConv1d(\n",
              "              (conv): NormConv1d(\n",
              "                (conv): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
              "                (norm): Identity()\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (shortcut): SConv1d(\n",
              "            (conv): NormConv1d(\n",
              "              (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "              (norm): Identity()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (11): ELU(alpha=1.0)\n",
              "        (12): SConv1d(\n",
              "          (conv): NormConv1d(\n",
              "            (conv): Conv1d(256, 512, kernel_size=(16,), stride=(8,))\n",
              "            (norm): Identity()\n",
              "          )\n",
              "        )\n",
              "        (13): SLSTM(\n",
              "          (lstm): LSTM(512, 512, num_layers=2)\n",
              "        )\n",
              "        (14): ELU(alpha=1.0)\n",
              "        (15): SConv1d(\n",
              "          (conv): NormConv1d(\n",
              "            (conv): Conv1d(512, 128, kernel_size=(7,), stride=(1,))\n",
              "            (norm): Identity()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (quantizer): ResidualVectorQuantizer(\n",
              "      (vq): ResidualVectorQuantization(\n",
              "        (layers): ModuleList(\n",
              "          (0-31): 32 x VectorQuantization(\n",
              "            (project_in): Identity()\n",
              "            (project_out): Identity()\n",
              "            (_codebook): EuclideanCodebook()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (decoder): SEANetDecoder(\n",
              "      (model): Sequential(\n",
              "        (0): SConv1d(\n",
              "          (conv): NormConv1d(\n",
              "            (conv): Conv1d(128, 512, kernel_size=(7,), stride=(1,))\n",
              "            (norm): Identity()\n",
              "          )\n",
              "        )\n",
              "        (1): SLSTM(\n",
              "          (lstm): LSTM(512, 512, num_layers=2)\n",
              "        )\n",
              "        (2): ELU(alpha=1.0)\n",
              "        (3): SConvTranspose1d(\n",
              "          (convtr): NormConvTranspose1d(\n",
              "            (convtr): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,))\n",
              "            (norm): Identity()\n",
              "          )\n",
              "        )\n",
              "        (4): SEANetResnetBlock(\n",
              "          (block): Sequential(\n",
              "            (0): ELU(alpha=1.0)\n",
              "            (1): SConv1d(\n",
              "              (conv): NormConv1d(\n",
              "                (conv): Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n",
              "                (norm): Identity()\n",
              "              )\n",
              "            )\n",
              "            (2): ELU(alpha=1.0)\n",
              "            (3): SConv1d(\n",
              "              (conv): NormConv1d(\n",
              "                (conv): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
              "                (norm): Identity()\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (shortcut): SConv1d(\n",
              "            (conv): NormConv1d(\n",
              "              (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "              (norm): Identity()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (5): ELU(alpha=1.0)\n",
              "        (6): SConvTranspose1d(\n",
              "          (convtr): NormConvTranspose1d(\n",
              "            (convtr): ConvTranspose1d(256, 128, kernel_size=(10,), stride=(5,))\n",
              "            (norm): Identity()\n",
              "          )\n",
              "        )\n",
              "        (7): SEANetResnetBlock(\n",
              "          (block): Sequential(\n",
              "            (0): ELU(alpha=1.0)\n",
              "            (1): SConv1d(\n",
              "              (conv): NormConv1d(\n",
              "                (conv): Conv1d(128, 64, kernel_size=(3,), stride=(1,))\n",
              "                (norm): Identity()\n",
              "              )\n",
              "            )\n",
              "            (2): ELU(alpha=1.0)\n",
              "            (3): SConv1d(\n",
              "              (conv): NormConv1d(\n",
              "                (conv): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
              "                (norm): Identity()\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (shortcut): SConv1d(\n",
              "            (conv): NormConv1d(\n",
              "              (conv): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
              "              (norm): Identity()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (8): ELU(alpha=1.0)\n",
              "        (9): SConvTranspose1d(\n",
              "          (convtr): NormConvTranspose1d(\n",
              "            (convtr): ConvTranspose1d(128, 64, kernel_size=(8,), stride=(4,))\n",
              "            (norm): Identity()\n",
              "          )\n",
              "        )\n",
              "        (10): SEANetResnetBlock(\n",
              "          (block): Sequential(\n",
              "            (0): ELU(alpha=1.0)\n",
              "            (1): SConv1d(\n",
              "              (conv): NormConv1d(\n",
              "                (conv): Conv1d(64, 32, kernel_size=(3,), stride=(1,))\n",
              "                (norm): Identity()\n",
              "              )\n",
              "            )\n",
              "            (2): ELU(alpha=1.0)\n",
              "            (3): SConv1d(\n",
              "              (conv): NormConv1d(\n",
              "                (conv): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
              "                (norm): Identity()\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (shortcut): SConv1d(\n",
              "            (conv): NormConv1d(\n",
              "              (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
              "              (norm): Identity()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (11): ELU(alpha=1.0)\n",
              "        (12): SConvTranspose1d(\n",
              "          (convtr): NormConvTranspose1d(\n",
              "            (convtr): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,))\n",
              "            (norm): Identity()\n",
              "          )\n",
              "        )\n",
              "        (13): SEANetResnetBlock(\n",
              "          (block): Sequential(\n",
              "            (0): ELU(alpha=1.0)\n",
              "            (1): SConv1d(\n",
              "              (conv): NormConv1d(\n",
              "                (conv): Conv1d(32, 16, kernel_size=(3,), stride=(1,))\n",
              "                (norm): Identity()\n",
              "              )\n",
              "            )\n",
              "            (2): ELU(alpha=1.0)\n",
              "            (3): SConv1d(\n",
              "              (conv): NormConv1d(\n",
              "                (conv): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
              "                (norm): Identity()\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (shortcut): SConv1d(\n",
              "            (conv): NormConv1d(\n",
              "              (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
              "              (norm): Identity()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (14): ELU(alpha=1.0)\n",
              "        (15): SConv1d(\n",
              "          (conv): NormConv1d(\n",
              "            (conv): Conv1d(32, 1, kernel_size=(7,), stride=(1,))\n",
              "            (norm): Identity()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "config=BarkConfig()\n",
        "model=Bark.init_from_config(config)\n",
        "model.load_checkpoint(config,checkpoint_dir=\"/content/bark\",eval=True)\n",
        "model.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEYZXOLdTuDp"
      },
      "outputs": [],
      "source": [
        "text=input(\"Enter the text: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OH6PfdZo6SDi"
      },
      "outputs": [],
      "source": [
        "output_dict = model.synthesize(\n",
        "    text,\n",
        "    config,\n",
        "    speaker_id=\"voice\",\n",
        "    voice_dirs=\"bark_voice\",\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1FeuWI59lp8"
      },
      "outputs": [],
      "source": [
        "write_wav(\"op.wav\",24000,output_dict[\"wav\"])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}